{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import IntegerType, StringType, DoubleType\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create Spark session\n",
    "spark = SparkSession.builder.appName('weather').getOrCreate()\n",
    "\n",
    "#change configuration settings on Spark \n",
    "conf = spark.sparkContext._conf.setAll([('spark.executor.memory', '5g'), ('spark.app.name', 'Spark Updated Conf'), ('spark.executor.cores', '4'), ('spark.cores.max', '4'), ('spark.driver.memory','8g')])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# shrink the dataset by selecting columns with less than 50% missing values\n",
    "year = ['2018', '2019', '2020', '2021', '2022']\n",
    "\n",
    "for y in year:\n",
    "    print('Starting to process ' + y + ' weather data')\n",
    "    df = spark.read \\\n",
    "        .option(\"quote\", \"\\\"\")  \\\n",
    "        .option(\"escape\", \"\\\"\") \\\n",
    "        .option(\"ignoreLeadingWhiteSpace\",True) \\\n",
    "        .csv(\"gs://mscabigdata7fall2022/\" + y + \".tar.gz\",inferSchema=True, header=True )\n",
    "    df = df.withColumnRenamed(df.columns[0], 'Station')\n",
    "    df.select('Station', 'DATE', 'LATITUDE', 'LONGITUDE', 'ELEVATION', 'NAME', 'REPORT_TYPE', 'SOURCE',\n",
    "                      'HourlyAltimeterSetting', 'HourlyDewPointTemperature', 'HourlyDryBulbTemperature', \n",
    "                       'HourlyRelativeHumidity', 'HourlyStationPressure', 'HourlyVisibility',\n",
    "                       'HourlyWetBulbTemperature','HourlyWindDirection', 'HourlyWindSpeed',  'REM')\\\n",
    "    .write.csv('gs://airline_project/' + y + 'weather.csv', mode=\"overwrite\", header=True)\n",
    "    print('Finish processing ' + y + ' weather data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------------+----------+----------+---------+-------------+-----------+------+----------------------+-------------------------+------------------------+----------------------+---------------------+----------------+------------------------+-------------------+---------------+--------------------+\n",
      "|    Station|               DATE|  LATITUDE| LONGITUDE|ELEVATION|         NAME|REPORT_TYPE|SOURCE|HourlyAltimeterSetting|HourlyDewPointTemperature|HourlyDryBulbTemperature|HourlyRelativeHumidity|HourlyStationPressure|HourlyVisibility|HourlyWetBulbTemperature|HourlyWindDirection|HourlyWindSpeed|                 REM|\n",
      "+-----------+-------------------+----------+----------+---------+-------------+-----------+------+----------------------+-------------------------+------------------------+----------------------+---------------------+----------------+------------------------+-------------------+---------------+--------------------+\n",
      "|38774099999|2022-01-01T02:00:00|38.4333333|57.4166666|    159.0|BAKHERDEN, TX|      FM-12|     4|                  null|                       28|                      32|                    86|                29.58|            1.24|                      31|                150|              2|SYN04838774 42995...|\n",
      "+-----------+-------------------+----------+----------+---------+-------------+-----------+------+----------------------+-------------------------+------------------------+----------------------+---------------------+----------------+------------------------+-------------------+---------------+--------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weather2022 = spark.read \\\n",
    "    .option(\"quote\", \"\\\"\")  \\\n",
    "    .option(\"escape\", \"\\\"\") \\\n",
    "    .option(\"ignoreLeadingWhiteSpace\",True) \\\n",
    "    .csv(\"gs://airline_project/2022weather.csv\",inferSchema=True, header=True )\n",
    "weather2022.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 13:=====================================================>(149 + 1) / 150]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+--------------------+--------------------+--------------------+--------------------+-----------+------+----------------------+-------------------------+------------------------+----------------------+---------------------+-------------------+------------------------+-------------------+-------------------+------------------+\n",
      "|Station|DATE|            LATITUDE|           LONGITUDE|           ELEVATION|                NAME|REPORT_TYPE|SOURCE|HourlyAltimeterSetting|HourlyDewPointTemperature|HourlyDryBulbTemperature|HourlyRelativeHumidity|HourlyStationPressure|   HourlyVisibility|HourlyWetBulbTemperature|HourlyWindDirection|    HourlyWindSpeed|               REM|\n",
      "+-------+----+--------------------+--------------------+--------------------+--------------------+-----------+------+----------------------+-------------------------+------------------------+----------------------+---------------------+-------------------+------------------------+-------------------+-------------------+------------------+\n",
      "|    0.0| 0.0|0.006606582350367989|0.006606582350367989|0.006628886134624...|0.006606582350367989|        0.0|   0.0|    0.4882206760396921|      0.17681917338817985|    0.028597202290047044|    0.1771338054380943|  0.47138001427442194|0.33289764049945125|     0.48145290208207026|0.15105553018733262|0.13956317199143534|0.1298972682900624|\n",
      "+-------+----+--------------------+--------------------+--------------------+--------------------+-----------+------+----------------------+-------------------------+------------------------+----------------------+---------------------+-------------------+------------------------+-------------------+-------------------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# check missing value\n",
    "amount_missing_2022 = weather2022.select([(count(when(isnan(c) | col(c).isNull(), c))/count(lit(1))).alias(c) for c in weather2022.columns])\n",
    "amount_missing_2022.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 18:=====================================================>(181 + 1) / 182]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+--------------------+--------------------+--------------------+--------------------+-----------+------+----------------------+-------------------------+------------------------+----------------------+---------------------+-------------------+------------------------+-------------------+-------------------+-------------------+\n",
      "|Station|DATE|            LATITUDE|           LONGITUDE|           ELEVATION|                NAME|REPORT_TYPE|SOURCE|HourlyAltimeterSetting|HourlyDewPointTemperature|HourlyDryBulbTemperature|HourlyRelativeHumidity|HourlyStationPressure|   HourlyVisibility|HourlyWetBulbTemperature|HourlyWindDirection|    HourlyWindSpeed|                REM|\n",
      "+-------+----+--------------------+--------------------+--------------------+--------------------+-----------+------+----------------------+-------------------------+------------------------+----------------------+---------------------+-------------------+------------------------+-------------------+-------------------+-------------------+\n",
      "|    0.0| 0.0|0.006726875023639018|0.006726875023639018|0.006752942355945...|0.006726875023639018|        0.0|   0.0|   0.49088795244692474|       0.1745176049920894|    0.024348538892316446|    0.1748460425306814|   0.4633847239218057|0.33597680931094737|      0.4740062087209283|0.14201073498307984|0.13097261455490267|0.13012501556271655|\n",
      "+-------+----+--------------------+--------------------+--------------------+--------------------+-----------+------+----------------------+-------------------------+------------------------+----------------------+---------------------+-------------------+------------------------+-------------------+-------------------+-------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "weather2021 = spark.read \\\n",
    "    .option(\"quote\", \"\\\"\")  \\\n",
    "    .option(\"escape\", \"\\\"\") \\\n",
    "    .option(\"ignoreLeadingWhiteSpace\",True) \\\n",
    "    .csv(\"gs://airline_project/2021weather.csv\",inferSchema=True, header=True )\n",
    "weather2021.select([(count(when(isnan(c) | col(c).isNull(), c))/count(lit(1))).alias(c) for c in weather2021.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 23:=====================================================>(183 + 1) / 184]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+--------------------+--------------------+--------------------+--------------------+-----------+------+----------------------+-------------------------+------------------------+----------------------+---------------------+-------------------+------------------------+-------------------+-------------------+------------------+\n",
      "|Station|DATE|            LATITUDE|           LONGITUDE|           ELEVATION|                NAME|REPORT_TYPE|SOURCE|HourlyAltimeterSetting|HourlyDewPointTemperature|HourlyDryBulbTemperature|HourlyRelativeHumidity|HourlyStationPressure|   HourlyVisibility|HourlyWetBulbTemperature|HourlyWindDirection|    HourlyWindSpeed|               REM|\n",
      "+-------+----+--------------------+--------------------+--------------------+--------------------+-----------+------+----------------------+-------------------------+------------------------+----------------------+---------------------+-------------------+------------------------+-------------------+-------------------+------------------+\n",
      "|    0.0| 0.0|0.006929802839948216|0.006929802839948216|0.006929802839948216|0.006929802839948216|        0.0|   0.0|    0.4896788598005991|       0.1735547533874002|      0.0223783169776123|      0.17399589971641|    0.459404137175807|0.33539488028999254|      0.4700243672456115| 0.1392424346095896|0.12879576212654645|0.1299240975997937|\n",
      "+-------+----+--------------------+--------------------+--------------------+--------------------+-----------+------+----------------------+-------------------------+------------------------+----------------------+---------------------+-------------------+------------------------+-------------------+-------------------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "weather2020 = spark.read \\\n",
    "    .option(\"quote\", \"\\\"\")  \\\n",
    "    .option(\"escape\", \"\\\"\") \\\n",
    "    .option(\"ignoreLeadingWhiteSpace\",True) \\\n",
    "    .csv(\"gs://airline_project/2020weather.csv\",inferSchema=True, header=True )\n",
    "weather2020.select([(count(when(isnan(c) | col(c).isNull(), c))/count(lit(1))).alias(c) for c in weather2020.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 28:=====================================================>(185 + 1) / 186]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+--------------------+--------------------+--------------------+--------------------+-----------+------+----------------------+-------------------------+------------------------+----------------------+---------------------+------------------+------------------------+-------------------+-------------------+-------------------+\n",
      "|Station|DATE|            LATITUDE|           LONGITUDE|           ELEVATION|                NAME|REPORT_TYPE|SOURCE|HourlyAltimeterSetting|HourlyDewPointTemperature|HourlyDryBulbTemperature|HourlyRelativeHumidity|HourlyStationPressure|  HourlyVisibility|HourlyWetBulbTemperature|HourlyWindDirection|    HourlyWindSpeed|                REM|\n",
      "+-------+----+--------------------+--------------------+--------------------+--------------------+-----------+------+----------------------+-------------------------+------------------------+----------------------+---------------------+------------------+------------------------+-------------------+-------------------+-------------------+\n",
      "|    0.0| 0.0|0.006283884970494543|0.006283884970494543|0.006283884970494543|0.006283884970494543|        0.0|   0.0|   0.48895395764860167|      0.16985092536044533|    0.021134850686824955|   0.17013237829205027|   0.4689028273105743|0.3378054954711792|     0.47884230371399567|0.13706882815566065|0.12708431988946808|0.12785884216199472|\n",
      "+-------+----+--------------------+--------------------+--------------------+--------------------+-----------+------+----------------------+-------------------------+------------------------+----------------------+---------------------+------------------+------------------------+-------------------+-------------------+-------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "weather2019 = spark.read \\\n",
    "    .option(\"quote\", \"\\\"\")  \\\n",
    "    .option(\"escape\", \"\\\"\") \\\n",
    "    .option(\"ignoreLeadingWhiteSpace\",True) \\\n",
    "    .csv(\"gs://airline_project/2019weather.csv\",inferSchema=True, header=True )\n",
    "weather2019.select([(count(when(isnan(c) | col(c).isNull(), c))/count(lit(1))).alias(c) for c in weather2019.columns]).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 33:=====================================================>(182 + 1) / 183]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+-------------------+-------------------+-------------------+-------------------+-----------+------+----------------------+-------------------------+------------------------+----------------------+---------------------+------------------+------------------------+-------------------+------------------+-------------------+\n",
      "|Station|DATE|           LATITUDE|          LONGITUDE|          ELEVATION|               NAME|REPORT_TYPE|SOURCE|HourlyAltimeterSetting|HourlyDewPointTemperature|HourlyDryBulbTemperature|HourlyRelativeHumidity|HourlyStationPressure|  HourlyVisibility|HourlyWetBulbTemperature|HourlyWindDirection|   HourlyWindSpeed|                REM|\n",
      "+-------+----+-------------------+-------------------+-------------------+-------------------+-----------+------+----------------------+-------------------------+------------------------+----------------------+---------------------+------------------+------------------------+-------------------+------------------+-------------------+\n",
      "|    0.0| 0.0|0.00741589729508956|0.00741589729508956|0.00741589729508956|0.00741589729508956|        0.0|   0.0|   0.48894221063265536|      0.17326799659590386|     0.02169944748583988|   0.17353504255034974|  0.46306729816778464|0.3381070270051364|      0.4723644387000636|0.13889405265869834|0.1283248534326405|0.13138341811168347|\n",
      "+-------+----+-------------------+-------------------+-------------------+-------------------+-----------+------+----------------------+-------------------------+------------------------+----------------------+---------------------+------------------+------------------------+-------------------+------------------+-------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "weather2018 = spark.read \\\n",
    "    .option(\"quote\", \"\\\"\")  \\\n",
    "    .option(\"escape\", \"\\\"\") \\\n",
    "    .option(\"ignoreLeadingWhiteSpace\",True) \\\n",
    "    .csv(\"gs://airline_project/2018weather.csv\",inferSchema=True, header=True )\n",
    "weather2018.select([(count(when(isnan(c) | col(c).isNull(), c))/count(lit(1))).alias(c) for c in weather2018.columns]).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# append all weather data\n",
    "weather = weather2018.union(weather2019).union(weather2020).union(weather2021).union(weather2022)\n",
    "weather.write.csv('gs://airline_project/weather.csv', mode=\"overwrite\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Station',\n",
       " 'DATE',\n",
       " 'LATITUDE',\n",
       " 'LONGITUDE',\n",
       " 'ELEVATION',\n",
       " 'NAME',\n",
       " 'REPORT_TYPE',\n",
       " 'SOURCE',\n",
       " 'HourlyAltimeterSetting',\n",
       " 'HourlyDewPointTemperature',\n",
       " 'HourlyDryBulbTemperature',\n",
       " 'HourlyRelativeHumidity',\n",
       " 'HourlyStationPressure',\n",
       " 'HourlyVisibility',\n",
       " 'HourlyWetBulbTemperature',\n",
       " 'HourlyWindDirection',\n",
       " 'HourlyWindSpeed',\n",
       " 'REM']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "624571145"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Station: string (nullable = true)\n",
      " |-- DATE: timestamp (nullable = true)\n",
      " |-- LATITUDE: double (nullable = true)\n",
      " |-- LONGITUDE: double (nullable = true)\n",
      " |-- ELEVATION: double (nullable = true)\n",
      " |-- NAME: string (nullable = true)\n",
      " |-- REPORT_TYPE: string (nullable = true)\n",
      " |-- SOURCE: string (nullable = true)\n",
      " |-- HourlyAltimeterSetting: double (nullable = true)\n",
      " |-- HourlyDewPointTemperature: double (nullable = true)\n",
      " |-- HourlyDryBulbTemperature: double (nullable = true)\n",
      " |-- HourlyRelativeHumidity: double (nullable = true)\n",
      " |-- HourlyStationPressure: double (nullable = true)\n",
      " |-- HourlyVisibility: double (nullable = true)\n",
      " |-- HourlyWetBulbTemperature: double (nullable = true)\n",
      " |-- HourlyWindDirection: double (nullable = true)\n",
      " |-- HourlyWindSpeed: double (nullable = true)\n",
      " |-- REM: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# change data types\n",
    "from pyspark.sql.functions import col, to_timestamp\n",
    "from pyspark.sql.types import IntegerType, BooleanType, StringType, DateType, DoubleType\n",
    "\n",
    "weather = weather.withColumn(\"DATE\", to_timestamp(col(\"DATE\")))\\\n",
    "    .withColumn(\"LATITUDE\", weather.LATITUDE.cast(DoubleType()))\\\n",
    "    .withColumn(\"LONGITUDE\", weather.LONGITUDE.cast(DoubleType()))\\\n",
    "    .withColumn(\"ELEVATION\", weather.ELEVATION.cast(DoubleType()))\\\n",
    "    .withColumn(\"HourlyAltimeterSetting\", weather.HourlyAltimeterSetting.cast(DoubleType()))\\\n",
    "    .withColumn(\"HourlyDewPointTemperature\", weather.HourlyDewPointTemperature.cast(DoubleType()))\\\n",
    "    .withColumn(\"HourlyDryBulbTemperature\", weather.HourlyDryBulbTemperature.cast(DoubleType()))\\\n",
    "    .withColumn(\"HourlyRelativeHumidity\", weather.HourlyRelativeHumidity.cast(DoubleType()))\\\n",
    "    .withColumn(\"HourlyStationPressure\", weather.HourlyStationPressure.cast(DoubleType()))\\\n",
    "    .withColumn(\"HourlyVisibility\", weather.HourlyVisibility.cast(DoubleType()))\\\n",
    "    .withColumn(\"HourlyWetBulbTemperature\", weather.HourlyWetBulbTemperature.cast(DoubleType()))\\\n",
    "    .withColumn(\"HourlyWindDirection\", weather.HourlyWindDirection.cast(DoubleType()))\\\n",
    "    .withColumn(\"HourlyWindSpeed\", weather.HourlyWindSpeed.cast(DoubleType()))\\\n",
    "    .withColumn(\"REM\", weather.REM.cast(DoubleType()))\n",
    "weather.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract day from date\n",
    "from pyspark.sql.functions import to_date\n",
    "weather = weather.withColumn('Day', to_date(weather.DATE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------------+--------+-----------+---------+--------+-----------+------+----------------------+-------------------------+------------------------+----------------------+---------------------+----------------+------------------------+-------------------+---------------+----+----------+\n",
      "|    Station|               DATE|LATITUDE|  LONGITUDE|ELEVATION|    NAME|REPORT_TYPE|SOURCE|HourlyAltimeterSetting|HourlyDewPointTemperature|HourlyDryBulbTemperature|HourlyRelativeHumidity|HourlyStationPressure|HourlyVisibility|HourlyWetBulbTemperature|HourlyWindDirection|HourlyWindSpeed| REM|       Day|\n",
      "+-----------+-------------------+--------+-----------+---------+--------+-----------+------+----------------------+-------------------------+------------------------+----------------------+---------------------+----------------+------------------------+-------------------+---------------+----+----------+\n",
      "|83811099999|2018-01-01 09:00:00|   -24.4|-50.8333333|    808.0|IVAI, BR|      FM-12|     4|                  null|                     69.0|                    71.0|                  91.0|                27.24|            6.21|                    70.0|              320.0|            2.0|null|2018-01-01|\n",
      "+-----------+-------------------+--------+-----------+---------+--------+-----------+------+----------------------+-------------------------+------------------------+----------------------+---------------------+----------------+------------------------+-------------------+---------------+----+----------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weather.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate by day level\n",
    "from pyspark.sql import functions as F\n",
    "weather_agg = weather.groupby('Station', 'Day').agg(F.avg('LATITUDE'),\n",
    "                                          F.avg('LONGITUDE'),\n",
    "                                          F.avg('ELEVATION'),\n",
    "                                F.avg('HourlyAltimeterSetting'),\n",
    "                                 F.avg('HourlyDewPointTemperature'),\n",
    "                                 F.avg('HourlyDryBulbTemperature'),\n",
    "                                 F.avg('HourlyRelativeHumidity'),\n",
    "                                 F.avg('HourlyStationPressure'),\n",
    "                                 F.avg('HourlyVisibility'),\n",
    "                                 F.avg('HourlyWetBulbTemperature'),\n",
    "                                 F.avg('HourlyWindDirection'),\n",
    "                                F.avg('HourlyWindSpeed'),\n",
    "                                F.avg('REM'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/11/08 22:19:49 WARN org.apache.spark.sql.catalyst.util.package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "[Stage 43:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+------------------+------------------+------------------+---------------------------+------------------------------+-----------------------------+---------------------------+--------------------------+---------------------+-----------------------------+------------------------+--------------------+--------+\n",
      "|    Station|       Day|     avg(LATITUDE)|    avg(LONGITUDE)|    avg(ELEVATION)|avg(HourlyAltimeterSetting)|avg(HourlyDewPointTemperature)|avg(HourlyDryBulbTemperature)|avg(HourlyRelativeHumidity)|avg(HourlyStationPressure)|avg(HourlyVisibility)|avg(HourlyWetBulbTemperature)|avg(HourlyWindDirection)|avg(HourlyWindSpeed)|avg(REM)|\n",
      "+-----------+----------+------------------+------------------+------------------+---------------------------+------------------------------+-----------------------------+---------------------------+--------------------------+---------------------+-----------------------------+------------------------+--------------------+--------+\n",
      "|59287099999|2018-03-23|23.392436000000007|113.29878600000006|15.240000000000007|         30.040624999999988|            49.392857142857146|                       67.875|         55.642857142857146|                   29.8175|     5.75767857142857|                        55.75|      139.33333333333334|   4.107142857142857|    null|\n",
      "+-----------+----------+------------------+------------------+------------------+---------------------------+------------------------------+-----------------------------+---------------------------+--------------------------+---------------------+-----------------------------+------------------------+--------------------+--------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "weather_agg.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "weather_agg.write.csv('gs://airline_project/weather_day.csv', mode=\"overwrite\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 56:=====================================================>(884 + 1) / 885]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+-----------------+-----------------+--------------+---------------------------+------------------------------+-----------------------------+---------------------------+--------------------------+---------------------+-----------------------------+------------------------+--------------------+--------+\n",
      "|    Station|       Day|    avg(LATITUDE)|   avg(LONGITUDE)|avg(ELEVATION)|avg(HourlyAltimeterSetting)|avg(HourlyDewPointTemperature)|avg(HourlyDryBulbTemperature)|avg(HourlyRelativeHumidity)|avg(HourlyStationPressure)|avg(HourlyVisibility)|avg(HourlyWetBulbTemperature)|avg(HourlyWindDirection)|avg(HourlyWindSpeed)|avg(REM)|\n",
      "+-----------+----------+-----------------+-----------------+--------------+---------------------------+------------------------------+-----------------------------+---------------------------+--------------------------+---------------------+-----------------------------+------------------------+--------------------+--------+\n",
      "|38774099999|2018-03-25|38.43333330000001|57.41666659999999|         159.0|                       null|                          47.0|                         84.5|                       28.0|                   29.2625|              6.67875|                       62.625|                  283.75|                 9.0|    null|\n",
      "+-----------+----------+-----------------+-----------------+--------------+---------------------------+------------------------------+-----------------------------+---------------------------+--------------------------+---------------------+-----------------------------+------------------------+--------------------+--------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# check if the lattitude and longitude works well\n",
    "weather_agg.where(weather_agg.Station == '38774099999').show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "21464177"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_agg.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 512:===============================>                         (5 + 4) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# create a new dataframe for station and the corresponding lat and long\n",
    "station_list = weather_agg.select('Station', 'avg(LATITUDE)', 'avg(LONGITUDE)').distinct()\n",
    "print(station_list.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 539:=========================>                               (4 + 4) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+------------------+\n",
      "|    Station|  Latitude|         Longitude|\n",
      "+-----------+----------+------------------+\n",
      "|71867099999|53.9666666|-101.1000000000001|\n",
      "+-----------+----------+------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 539:============================================>            (7 + 2) / 9]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "station_list.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average the long and lat in case the same station shares different long and lat in different years\n",
    "station_list = station_list.groupby('Station').agg(F.avg('avg(LATITUDE)').alias('Latitude'),\n",
    "                                          F.avg('avg(LONGITUDE)').alias('Longitude'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "station_list.write.csv('gs://airline_project/station_list.csv', mode=\"overwrite\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "82015"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if the all stations are unique\n",
    "station_list.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "82015"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "station_list.select('Station').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 551:============================>                            (2 + 2) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|Station|count|\n",
      "+-------+-----+\n",
      "+-------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "station_list.groupby('Station').count().filter('count > 1').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read \\\n",
    "    .option(\"quote\", \"\\\"\")  \\\n",
    "    .option(\"escape\", \"\\\"\") \\\n",
    "    .option(\"ignoreLeadingWhiteSpace\",True) \\\n",
    "    .csv(\"gs://mscabigdata7fall2022/weather_day.csv/\",inferSchema=True, header=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}